# ðŸ“¡ YoutubeReditCrawler

## ðŸ” Overview

**YoutubeReditCrawler** is a Python-based project designed to scrape and analyze **Lebanese Arabizi** comments from Reddit and YouTube. It continuously monitors content, detects Arabizi text, and stores relevant comments in a structured format for further processing or training.

---

## âœ¨ Features

- ðŸ” Scrapes comments from Reddit (`old.reddit.com`) and YouTube
- ðŸ§  Detects Lebanese Arabizi comments using a custom classifier
- ðŸ’¾ Stores relevant comments in a `.jsonl` file
- ðŸ—ƒ Tracks processed content using an SQLite database

---

## ðŸ“¦ Installation

1. Ensure **Python 3.8+** is installed.

2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```

---

## âš™ï¸ Configuration

Create a `sample.json` configuration file in the root directory with this structure:

```json
{
  "subreddits": ["lebanon", "beirut"],
  "youtube_videos": ["https://www.youtube.com/watch?v=aoUEXRlvmxc"],
  "single_reddit_post": "https://old.reddit.com/r/lebanon/comments/18k7z8v/what_are_your_thoughts_on_the_current_situation/",
  "single_youtube_video": "https://www.youtube.com/watch?v=aoUEXRlvmxc"
}
```

- `subreddits`: List of subreddits to crawl
- `youtube_videos`: List of YouTube video URLs
- `single_reddit_post`: (Optional) Scrape a single Reddit post
- `single_youtube_video`: (Optional) Scrape a single YouTube video

---

## â–¶ï¸ Usage

1. Ensure all required files are in the same directory:
   - `main.py`
   - `reddit_crawler.py`
   - `youtube_crawler.py`
   - `classifier.py`
   - `database.py`
   - `sample.json`
   - `requirements.txt`

2. Run the script:
   ```bash
   python main.py
   ```

3. Output:
   - `comments.jsonl` â€” Saved Arabizi comments
   - `crawler.db` â€” SQLite database tracking processed posts/videos

---

## ðŸ§± Project Structure

```
YoutubeReditCrawler/
â”œâ”€â”€ main.py               # Entry point
â”œâ”€â”€ reddit_crawler.py     # Reddit scraping logic
â”œâ”€â”€ youtube_crawler.py    # YouTube scraping logic
â”œâ”€â”€ classifier.py         # Lebanese Arabizi classifier
â”œâ”€â”€ database.py           # SQLite database management
â”œâ”€â”€ sample.json           # Configuration file
â”œâ”€â”€ requirements.txt      # Dependencies
â”œâ”€â”€ comments.jsonl        # Output file (generated)
â””â”€â”€ crawler.db            # SQLite database (generated)
```

---

## License

This project is licensed under the [MIT License](LICENSE).

If you use this project, **you must provide attribution** by stating:
> "This project is based on code created by Moosa Ali â€“ [https://github.com/MusaShah100/YoutubeReditCrawler]".

## ðŸ‘¤ Author

**Syed Moosa Ali**
